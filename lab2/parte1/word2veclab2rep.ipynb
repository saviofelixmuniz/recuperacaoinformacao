{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Parte 1 - Reposição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta atividade foi realizada com o propósito de aprender sobre e construir um modelo Word2Vec. Este algoritmo consiste em transformar palavras em vetores, de forma a dispô-las em um espaço vetorial e tornando possível realização de operações matemáticas. Neste exercício, o foco será na distância entre tokens vetorizados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Início"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, faz-se os imports das bibliotecas que serão utilizadas e define-se a __função de padronização de texto__, que serve para remoção de __caracteres especiais__ e para deixar todas as palavras em __letras minúsculas__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from unidecode import unidecode\n",
    "import warnings\n",
    "import gensim\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def standardize_text(text):\n",
    "    return unidecode(''.join(e for e in text if (e.isalnum() or e ==' ')).lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feito isso, deseja-se agora __carregar os dados__ de estudo, que neste caso trata-se de uma coleção de notícias do portal Estadão. Neste processo, __três coisas__ devem ser feitas:\n",
    "1. Concatenar título, sub-título e corpo das notícias;\n",
    "2. Usar a função de padronização no resultado da concatenação;\n",
    "3. Criar uma lista de tokens(palavras) usando o split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "with open('estadao_noticias_eleicao.csv', 'rt', encoding='utf8') as csvfile:\n",
    "    estadao = csv.reader(csvfile)\n",
    "    for index, article in enumerate(estadao):\n",
    "        if index == 0:\n",
    "            continue\n",
    "            \n",
    "        article_content = article[1] + \" \" + article[2] + \" \" + article[3]\n",
    "        documents.append(standardize_text(article_content).split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível, agora, observar uma parte do resultado de carregamento para o primeiro documento da coleção:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pt',\n",
       " 'espera',\n",
       " '30',\n",
       " 'mil',\n",
       " 'pessoas',\n",
       " 'em',\n",
       " 'festa',\n",
       " 'na',\n",
       " 'esplanada',\n",
       " 'objetivo']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os dados necessários em mãos, se torna simples __treinar o modelo__. Deve ser passado para a biblioteca Gensim, uma __lista de listas de palavras__ (definida na seção anterior), __gerar o modelo__, e __treiná-lo__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27508697, 36779450)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O treinamento do modelo pode demorar um pouco. Por baixo, o Gensim constroi uma rede neural, da qual deseja-se extrair os pesos gerados, que representam os vetores das palavras. \n",
    "O Gensim prover, também, um conjunto de funções que tornam trivial a __obtenção de respostas para perguntas que podem ser muito relevantes__, como: \n",
    "1. __Uma palavra está relacionada com uma outra?__\n",
    "2. __Dado um conjunto de palavras, existe alguma que não faz sentido estar naquele conjunto?__\n",
    "3. __Dada uma palavra, quais são as n palavras mais parecidas com esta?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade entre duas palavras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível observar similaridade entre duas palavras usando a função __similarity__ do modelo. O retorno é um coeficiente que está entre 0 e 1, sendo que quanto mais próximo de 1, mais próximas as palavras estão no espaço vetorial e, portanto, mais similares elas são. Abaixo, alguns exemplos foram dispostos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055565123"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"bolsonaro\",w2=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23505023"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"dilma\",w2=\"presidente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54128206"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"silas\",w2=\"gay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vê-se portanto que os termos: __bolsonaro__ e __pt__ estão pouco relacionados; __dilma__ e __presidente__ possuem uma proximidade mais significativa; __silas__ e __gay__ tem ainda mais proximidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palavra estranha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função __doesnt_match__ por outro lado é útil na busca por palavras que menos se encaixam com o resto em um conjunto de palavras. Num conjunto de palavras em que se tem: __bolsonaro__, __pt__ e __dilma__, por exemplo, espera-se que bolsonaro seja a palavra menos relacionada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bolsonaro'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"bolsonaro\", \"pt\", \"dilma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cachorro'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"cachorro\", \"ingles\", \"frances\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brasil'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"pastor\", \"brasil\", \"silas\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 similares/mais próximas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, e principal objetivo desta atividade, é possível encontrar os __n termos mais próximos__ de uma palavra, usando a função __most_similar__. Nesta atividade, foi escolhido descobrir os dez termos mais parecidos com: __ciro__; __pt__; __bolsonaro__. Abaixo é possível ver os resultados obtidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nogueira', 0.6924452781677246),\n",
       " ('gomes', 0.6457257866859436),\n",
       " ('cid', 0.6340566277503967),\n",
       " ('pppi', 0.6028022766113281),\n",
       " ('pi', 0.5905863642692566),\n",
       " ('pros', 0.5849493741989136),\n",
       " ('camilo', 0.5513368844985962),\n",
       " ('eunicio', 0.4734727144241333),\n",
       " ('ceara', 0.46999669075012207),\n",
       " ('pp', 0.46808090806007385)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar (positive=\"ciro\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('petista', 0.6563131213188171),\n",
       " ('petistas', 0.5065073370933533),\n",
       " ('partido', 0.4542264938354492),\n",
       " ('dem', 0.38896244764328003),\n",
       " ('oposicionista', 0.36980316042900085),\n",
       " ('psb', 0.36759695410728455),\n",
       " ('pc', 0.36663487553596497),\n",
       " ('legenda', 0.3600459694862366),\n",
       " ('pr', 0.3457217812538147),\n",
       " ('medo', 0.3447813093662262)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar (positive=\"pt\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jair', 0.8037880659103394),\n",
       " ('pprj', 0.7005596160888672),\n",
       " ('feliciano', 0.679299533367157),\n",
       " ('wyllys', 0.6612508296966553),\n",
       " ('psolrj', 0.6033853888511658),\n",
       " ('jean', 0.5905729532241821),\n",
       " ('heinze', 0.571237325668335),\n",
       " ('malafaia', 0.5456973314285278),\n",
       " ('comprometedor', 0.5443352460861206),\n",
       " ('jandira', 0.5385400056838989)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar (positive=\"bolsonaro\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prova-se nessa atividade o quanto é simples a construção de um modelo __Word2Vec__ usando a biblioteca __gensim__ e, ao mesmo tempo, o quanto os resultados podem ser relavantes. Alguns casos de uso possíveis para este modelo são, por exemplo: entender como estão falando de um produto, num banco de reviews; construir um dicionário de sinônimos; sugerir palavras conforme se digita."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
