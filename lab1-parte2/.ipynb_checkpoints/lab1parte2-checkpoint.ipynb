{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Parte 2 - Ranking e Modelo Vetorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta atividade, foi feita a implementação de alguns algoritmos de busca usando o modelo vetorial. O índice invertido da primeira parte da atividade foi reaproveitado e melhorado para que este fim fosse atingido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, foram importadas as bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import timeit\n",
    "import operator\n",
    "import math\n",
    "import random\n",
    "import ast\n",
    "from unidecode import unidecode\n",
    "from sortedcontainers import SortedList\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E definida uma função para regularizar o texto, tirando todos os caracteres especiais e acentuações que fossem encontrados nestes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(text):\n",
    "    return unidecode(''.join(e for e in text if (e.isalnum() or e ==' ')).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice invertido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciam-se as variáveis que ajudarão na definição do ínidice invertido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = dict()\n",
    "page_tf = dict()\n",
    "general_tf = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para então definir as funções necessárias para o funcionamento do índice invertido: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(page_id, text):\n",
    "    word_counts = Counter(text.split(' '))\n",
    "    page_tf[page_id] = word_counts\n",
    "\n",
    "    for word in word_counts:\n",
    "        if word not in general_tf:\n",
    "            general_tf[word] = 0\n",
    "\n",
    "        general_tf[word] += word_counts[word]\n",
    "\n",
    "        if word not in inverted_index:\n",
    "            inverted_index[word] = SortedList()\n",
    "\n",
    "        if page_id not in inverted_index[word]:\n",
    "            inverted_index[word].add(page_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_fill_ é responsável por encher o índice invertido através de um texto recebido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postings(term):\n",
    "    return inverted_index[term]\n",
    "\n",
    "\n",
    "def get_tf(term, page_id):\n",
    "    return page_tf[page_id][term]\n",
    "\n",
    "\n",
    "def get_general_tf(term):\n",
    "    return general_tf[term]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*get_postings*, *get_tf* e *get_general_tf* retornam a lista de documentos em um termo é encontrado, a frequência de um termo em um documento e a frequência de um termo em todos os documentos, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_idf(word):\n",
    "    return math.log((len(inverted_index) + 1)/len(inverted_index[word]))\n",
    "\n",
    "def calculate_bm25(word,page):\n",
    "    k = random.random() * 0.8 + 1.2\n",
    "\n",
    "    return calculate_idf(word) * ((get_tf(word, page) * (k + 1))/(get_tf(word, page) + k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui foram definidas as duas funções que realizam os cálculos que serão necessários no modelo, uma de IDF, que segue a seguinte fórmula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$IDF = log\\frac{M + 1}{k}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em que M é o número de termos no índice invertido e k é o número de documentos que o termo é encontrado. \n",
    "A outra função define o cálculo de score BM25, que segue a fórmula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$score = IDF * \\frac{f(t,D) * (k + 1)}{f(t,D) + k}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em que f(t,D) é a frequência de um termo em um documento e k é uma constante com valor aleatório entre 1.2 e 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se então agora, finalmente, definir as funções de busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(sentence, method):\n",
    "    standardized_sentence = standardize_text(sentence)\n",
    "    words = standardized_sentence.split(' ')\n",
    "\n",
    "    return {\n",
    "        'tf': score_search(words, 'tf'),\n",
    "        'tfidf': score_search(words, 'idf'),\n",
    "        'bm25': score_search(words, 'bm25'),\n",
    "        'binary': binary_search(words)\n",
    "    }[method]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*search* define qual dos 4 métodos usar, sendo que o **binary** já tinha sido implementado na atividade passada. Revisando o algoritmo usado para este, tem-se:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(word_list):\n",
    "    if len(word_list) == 1:\n",
    "        return get_postings(word_list[0])\n",
    "\n",
    "    results = None\n",
    "\n",
    "    for i in range(1, len(word_list)):\n",
    "        if i == 1:\n",
    "            results = merge_results(get_postings(word_list[0]), get_postings(word_list[1]))\n",
    "\n",
    "        else:\n",
    "            results = merge_results(results, get_postings(word_list[i]))\n",
    "\n",
    "    return results\n",
    "\n",
    "def merge_results(first_list, second_list):\n",
    "    results = SortedList()\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    while True:\n",
    "        if first_list[i] == second_list[j]:\n",
    "            results.add(first_list[i])\n",
    "\n",
    "        if first_list[i] > second_list[j]:\n",
    "            j += 1\n",
    "            if j == len(second_list):\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            i += 1\n",
    "            if i == len(first_list):\n",
    "                break\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se então, por fim, definir as buscas rankeadas com a função *score_search*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_search(word_list, model):\n",
    "    results = binary_search(word_list)\n",
    "\n",
    "    sorted_results = []\n",
    "\n",
    "    for page in results:\n",
    "        total_score = 0\n",
    "\n",
    "        for word in word_list:\n",
    "            if model == 'bm25':\n",
    "                score = calculate_bm25(word, page)\n",
    "            else:\n",
    "                score = get_tf(word, page) * (1 if model == 'tf' else calculate_idf(word))\n",
    "\n",
    "            total_score += score\n",
    "\n",
    "        sorted_results.append({'id': page, 'score': total_score})\n",
    "\n",
    "    sorted_results.sort(key=operator.itemgetter('score'), reverse=True)\n",
    "    return [e['id'] for e in sorted_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função segue a mesma estrutura para os três métodos (bm25, tf e tf-idf) a única diferença é na hora de calcular o score para cada sentença de busca. No bm25 usa-se a função de cálculo do score de bm25, no tf pega-se a frequência de cada termo no documento e no tf-idf usa-se a frequência de termo no documento e multipla-se pelo idf de uma palavra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, o índice invertido fica definido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo a busca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer a busca, importam-se os dados e enche-se o índice invertido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_list(article_sections):\n",
    "    return ' '.join(str(e) for e in article_sections)\n",
    "\n",
    "ID_INDEX = 5\n",
    "with open('estadao_noticias_eleicao.csv', 'rt', encoding='utf8') as csvfile:\n",
    "    estadao = csv.reader(csvfile)\n",
    "\n",
    "    for index, text_row in enumerate(estadao):\n",
    "        if index == 0:\n",
    "            continue\n",
    "\n",
    "        pageId = int(text_row[ID_INDEX])\n",
    "        content = standardize_text(join_list(text_row[1:4]))\n",
    "\n",
    "        fill(pageId, content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O sub-array definido das posições de 1 a 4 e a função *join_list* servem para juntar título, sub-título e conteúdo do documento em uma só string, dessa forma torna-se mais fácil o preenchimento do índice invertido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora é possível fazer a busca de termos usando a função *search* e escolhendo um dos métodos. Por exemplo, pode ser feito a busca: 'lula bolsonaro'. Fazendo *search('lula bolsonaro', 'tf')*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[932, 43, 46, 2187]\n"
     ]
    }
   ],
   "source": [
    "print(search('lula bolsonaro', 'tf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vê-se portanto, que quatro documentos tem os termos lula **E** bolsonaro e desses, o mais relevante, pelo método **tf**, é o documento 932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[932, 2187, 46, 43]\n"
     ]
    }
   ],
   "source": [
    "print(search('lula bolsonaro', 'bm25'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mudando de método vê-se que o 2187 que era o último em relevância, passou a ser segundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corretude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A parte final da atividade consistia em definição de corretude de acordo com um gabarito fornecido. Para auxiliar nessa parte, foi usada função pronta *MAPK*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa-se, então, o gabarito:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_SENTENCE_INDEX = 0\n",
    "GOOGLE_ANSWER_INDEX = 1\n",
    "TF_ANSWER_INDEX = 3\n",
    "TF_IDF_ANSWER_INDEX = 4\n",
    "BM25_ANSWER_INDEX = 5\n",
    "\n",
    "search_sentences =[]\n",
    "correct_answer_sheet = {'google' : [], 'tf': [], 'tfidf': [], 'bm25': []}\n",
    "\n",
    "with open('gabarito.csv', 'rt', encoding='utf8') as csvfile:\n",
    "    gabarito = csv.reader(csvfile)\n",
    "   \n",
    "    for index, row in enumerate(gabarito):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        \n",
    "        search_sentences.append(row[SEARCH_SENTENCE_INDEX])\n",
    "        correct_answer_sheet['google'].append(ast.literal_eval(row[GOOGLE_ANSWER_INDEX]))\n",
    "        correct_answer_sheet['tf'].append(ast.literal_eval(row[TF_ANSWER_INDEX]))\n",
    "        correct_answer_sheet['tfidf'].append(ast.literal_eval(row[TF_IDF_ANSWER_INDEX]))\n",
    "        correct_answer_sheet['bm25'].append(ast.literal_eval(row[BM25_ANSWER_INDEX]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E agora, usando os mesmos termos, cria-se a resposta da atividade usando os modelos implementados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_answer_sheet = {'tf': [], 'tfidf': [], 'bm25': []}\n",
    "for search_sentence in search_sentences:\n",
    "    for model in our_answer_sheet:\n",
    "        our_answer_sheet[model].append(search(search_sentence, model)[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, calcula-se a a corretude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = {}\n",
    "for model in our_answer_sheet:\n",
    "    accuracy[model] = mapk(correct_answer_sheet[model], our_answer_sheet[model],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tf': 0.9199999999999999, 'tfidf': 0.5453333333333333, 'bm25': 0.41}\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, comparando com a do google:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_accuracy = {}\n",
    "for model in our_answer_sheet:\n",
    "    google_accuracy[model] = mapk(correct_answer_sheet['google'], our_answer_sheet[model],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tf': 0.048, 'tfidf': 0.048, 'bm25': 0.12000000000000002}\n"
     ]
    }
   ],
   "source": [
    "print(google_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viu-se que, por mais que o acerto tenha sido baixo, o bm25 foi o modelo que mais se aproximou da resposta dada pelo Google. Isso porque este é o único dos modelos que tenta usar normalização para que uma palavra que é considerada relevante, porém muito repetida, não garanta, necessariamente, um score muito alto para um documento.   \n",
    "Além disso, comparando o gabarito e as respostas obtidas, viu-se que o maior acerto foi o do modelo tf e o menor foi o modelo bm25, isso era esperado porque o modelo bm25 usa uma variável aleatória, como a lista de acerto era pequena então se os valores de *k* fossem muito diferentes poderia afetar bastante a resposta. Os modelos *idf* e *tf* estarem com acurácia diferente de 100% causa estranheza, mas acredita-se que isto ocorreu porque o algoritmo de busca binária conjuntiva, da primeira atividade, foi reaproveitado, descartando então documentos em que não houvessem todas as palavras da pesquisa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
